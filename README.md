# Multi-Collection RAG Chatbot ğŸ¤–ğŸ“š

A powerful Retrieval-Augmented Generation (RAG) chatbot with **multi-collection support**, allowing you to organize and query different document sets independently.

## âœ¨ Key Features

- ğŸ—‚ï¸ **Multi-Collection Support** - Create unlimited collections for different topics/projects
- ğŸ” **Intelligent Retrieval** - Semantic search using HuggingFace embeddings
- ğŸ’¬ **Natural Conversations** - Powered by Google Gemini 2.5-Flash
- ğŸ“„ **Source Tracking** - View the exact chunks used to generate answers
- ğŸ¨ **Modern UI** - Clean Streamlit interface with collection management
- ğŸš€ **FastAPI Backend** - RESTful API architecture for scalability
- ğŸ“Š **Semantic Chunking** - Context-aware document splitting
- ğŸ’¾ **Persistent Storage** - ChromaDB vector database

## ğŸ†• What's New in v2.0

### Multi-Collection Architecture
- **Create separate collections** for different document sets
- **Independent context** per collection (no cross-contamination)
- **Easy switching** between collections via dropdown
- **Collection management** - create, query, list, delete

### Enhanced UI
- Collection selector in sidebar
- Collection info display (chunk counts)
- Collection-aware ingestion
- Visual feedback for active collection

### Improved API
- Collection-based endpoints
- List all collections with statistics
- Collection-specific querying
- Selective collection deletion
- **Background ingestion** with job tracking
- Chunking strategy selector (semantic/fixed)
- Real-time ingestion status updates

## ğŸš€ Quick Start

### Prerequisites
- Python 3.12+
- Virtual environment (recommended)

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd chatbot-application-with-RAG
```

2. Create and activate virtual environment:
```bash
python -m venv .venv
.venv\Scripts\activate  # Windows
# or
source .venv/bin/activate  # Linux/Mac
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Set up environment variables:
Create a `.env` file with your Google API key:
```
GOOGLE_API_KEY=your_api_key_here
```

### Running the Application

**Easy Method - Use Batch Scripts:**

1. **Start Backend:** Double-click `start_backend.bat`
2. **Start Frontend:** Double-click `start_frontend.bat`

**Manual Method:**

#### Step 1: Start FastAPI Backend
```bash
python -m uvicorn backend.api:app --reload --host 0.0.0.0 --port 8000
```
API will run on http://localhost:8000

#### Step 2: Start Streamlit UI
```bash
streamlit run frontend\app_api.py
```
UI will open at http://localhost:8501

**Legacy App (without API):**
```bash
streamlit run app\app.py
```

#### Step 3: Create Collections & Upload Documents
1. Go to **Ingestion** tab
2. Enter a collection name (e.g., "research_papers")
3. Choose chunking strategy (Semantic or Fixed-size)
4. Upload PDF file
5. Click **Ingest Document**
6. Ingestion runs in background - track status in UI
7. Wait 2-5 minutes for processing to complete

#### Step 4: Query Your Documents
1. Select collection from dropdown
2. Ask questions in the chat
3. Get answers with source chunks!

## ğŸ“ Project Structure

```
chatbot-application-with-RAG/
â”œâ”€â”€ backend/              # FastAPI backend
â”‚   â”œâ”€â”€ api.py           # FastAPI endpoints & RAG system
â”‚   â”œâ”€â”€ database.py      # SQLAlchemy models for job tracking
â”‚   â”œâ”€â”€ ingest.py        # Document ingestion logic
â”‚   â””â”€â”€ query.py         # RAG query logic
â”œâ”€â”€ frontend/            # Streamlit UI (API-based)
â”‚   â””â”€â”€ app_api.py       # Main Streamlit app with API calls
â”œâ”€â”€ app/                 # Legacy standalone app
â”‚   â””â”€â”€ app.py           # Streamlit app without API
â”œâ”€â”€ data/                # PDF documents (if any)
â”œâ”€â”€ Vector_DB/           # ChromaDB storage (gitignored)
â”œâ”€â”€ .venv/               # Virtual environment (gitignored)
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ .env                 # Environment variables (gitignored)
â”œâ”€â”€ start_backend.bat    # Quick start script for API
â”œâ”€â”€ start_frontend.bat   # Quick start script for UI
â””â”€â”€ README.md            # This file
```

## ğŸ—ï¸ Architecture

![System Architecture](images/chat-RAG-mermaid-diagram.png)

## ğŸ”§ Technology Stack

| Component | Technology |
|-----------|-----------|
| **Frontend** | Streamlit |
| **Backend** | FastAPI |
| **LLM** | Google Gemini 2.5-Flash |
| **Embeddings** | HuggingFace (all-mpnet-base-v2) |
| **Vector DB** | ChromaDB |
| **Chunking** | SemanticChunker + RecursiveCharacterTextSplitter |
| **Job Tracking** | SQLAlchemy + SQLite |

## ğŸ¯ Use Cases

### Research Papers
- Collection: "ml_papers" - Machine Learning research
- Collection: "quantum_papers" - Quantum Computing papers
- Collection: "bio_papers" - Biology research

### Project Documentation
- Collection: "project_alpha" - Alpha project docs
- Collection: "project_beta" - Beta project docs
- Collection: "project_gamma" - Gamma project docs

### Multi-Domain Knowledge Base
- Collection: "technical_docs" - Technical documentation
- Collection: "business_docs" - Business documents
- Collection: "legal_docs" - Legal documents

## ğŸ”Œ API Endpoints

### GET /health
Check API health and database status

### GET /collections
List all collections with chunk counts

### POST /query
Query a specific collection
```json
{
  "question": "What is a transformer?",
  "collection_name": "research_papers"
}
```

### POST /ingest
Ingest PDF to collection (background processing)
```
Form Data:
- file: PDF file
- collection_name: "my_collection"
- chunking_strategy: "semantic" or "fixed"
Returns: {"ingestion_id": "uuid", "message": "..."}
```

### GET /status/{ingestion_id}
Check ingestion job status
```json
Response: {
  "status": "PROCESSING",
  "progress": 45.5,
  "message": "Processing document..."
}
```

### GET /ingestions
List recent ingestion jobs with status

### DELETE /database
Delete entire database or specific collection
```
Query Parameter:
- collection_name: "specific_collection" (optional)
```

## ğŸ¨ UI Features

- **Collection Selector** - Dropdown to choose active collection
- **Chat Interface** - Multi-session chat history
- **Source Chunks** - Expandable view of retrieved context
- **Document Upload** - Drag-and-drop PDF ingestion
- **Collection Info** - Display chunk counts per collection
- **Session Management** - Create, switch, delete chat sessions

## ğŸ› ï¸ Troubleshooting

### API Not Responding
- **Issue**: Streamlit shows connection errors
- **Solution**: Ensure FastAPI is running on http://localhost:8000
- **Check**: Run `curl http://localhost:8000/health` or visit in browser

### Collection Name Validation Error
- **Issue**: "Invalid collection name" error
- **Solution**: Use only alphanumeric characters, dots, underscores, hyphens
- **Valid**: `research_papers`, `my-docs`, `collection.v1`
- **Invalid**: `my docs` (space), `report ` (trailing space)

### Ingestion Fails with 500 Error
- **Issue**: Ingestion returns server error
- **Solution**: 
  - Check API logs for detailed error
  - Ensure PDF is valid and not corrupted
  - Verify collection name is properly formatted
  - Restart API if needed

### Empty Collections Appearing
- **Issue**: Default collection shows with 0 chunks
- **Solution**: This is fixed in latest version - only collections with documents are loaded

### Background Ingestion Stuck
- **Issue**: Ingestion status stays at "PROCESSING"
- **Solution**:
  - Check `/ingestions` endpoint for error details
  - Large PDFs may take 5-10 minutes
  - Restart API if truly stuck

## ğŸ“ Collection Naming Rules

Collection names must:
- Be at least 3 characters long
- Start and end with alphanumeric characters
- Contain only: letters, numbers, dots (.), underscores (_), hyphens (-)
- **No spaces or trailing whitespace**

Examples:
âœ… `research_papers_2024`
âœ… `my-collection.v2`
âœ… `project_alpha`
âŒ `my collection` (space)
âŒ `report ` (trailing space)
âŒ `ab` (too short)

