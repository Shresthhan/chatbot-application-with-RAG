# Multi-Collection RAG Chatbot ğŸ¤–ğŸ“š

A powerful Retrieval-Augmented Generation (RAG) chatbot with **multi-collection support**, allowing you to organize and query different document sets independently.

## âœ¨ Key Features

- ğŸ—‚ï¸ **Multi-Collection Support** - Create unlimited collections for different topics/projects
- ğŸ” **Intelligent Retrieval** - Semantic search using HuggingFace embeddings
- ğŸ’¬ **Natural Conversations** - Powered by Google Gemini 2.5-Flash
- ğŸ“„ **Source Tracking** - View the exact chunks used to generate answers
- ğŸ¨ **Modern UI** - Clean Streamlit interface with collection management
- ğŸš€ **FastAPI Backend** - RESTful API architecture for scalability
- ğŸ“Š **Semantic Chunking** - Context-aware document splitting
- ğŸ’¾ **Persistent Storage** - ChromaDB vector database

## ğŸ†• What's New in v2.0

### Multi-Collection Architecture
- **Create separate collections** for different document sets
- **Independent context** per collection (no cross-contamination)
- **Easy switching** between collections via dropdown
- **Collection management** - create, query, list, delete

### Enhanced UI
- Collection selector in sidebar
- Collection info display (chunk counts)
- Collection-aware ingestion
- Visual feedback for active collection

### Improved API
- Collection-based endpoints
- List all collections with statistics
- Collection-specific querying
- Selective collection deletion

## ğŸš€ Quick Start

### Prerequisites
- Python 3.12+
- Virtual environment (recommended)

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd chatbot-application-with-RAG
```

2. Create and activate virtual environment:
```bash
python -m venv .venv
.venv\Scripts\activate  # Windows
# or
source .venv/bin/activate  # Linux/Mac
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Set up environment variables:
Create a `.env` file with your Google API key:
```
GOOGLE_API_KEY=your_api_key_here
```

### Running the Application

#### Step 1: Start FastAPI Backend
```bash
.venv\Scripts\python.exe api.py
```
API will run on http://localhost:8000

#### Step 2: Start Streamlit UI
```bash
.venv\Scripts\python.exe -m streamlit run app_api.py
```
UI will open at http://localhost:8501

#### Step 3: Create Collections & Upload Documents
1. Go to **Ingestion** tab
2. Enter a collection name (e.g., "research_papers")
3. Upload PDF file
4. Click **Ingest Document**
5. Wait 2-5 minutes for processing

#### Step 4: Query Your Documents
1. Select collection from dropdown
2. Ask questions in the chat
3. Get answers with source chunks!

## ğŸ“– Documentation

- **[QUICKSTART.md](QUICKSTART.md)** - Get started in 3 steps
- **[MULTI_COLLECTION_GUIDE.md](MULTI_COLLECTION_GUIDE.md)** - Comprehensive guide for collections
- **[ARCHITECTURE.md](ARCHITECTURE.md)** - System architecture and data flow
- **[IMPLEMENTATION_SUMMARY.md](IMPLEMENTATION_SUMMARY.md)** - Technical implementation details

## ğŸ—ï¸ Architecture

```
Streamlit UI (app_api.py)
    â†“ REST API calls
FastAPI Backend (api.py)
    â†“ Collection-specific queries
ChromaDB Vector Database
    â”œâ”€â”€ Collection: my_docss
    â”œâ”€â”€ Collection: research_papers
    â””â”€â”€ Collection: technical_docs
```

## ğŸ”§ Technology Stack

| Component | Technology |
|-----------|-----------|
| **Frontend** | Streamlit |
| **Backend** | FastAPI |
| **LLM** | Google Gemini 2.5-Flash |
| **Embeddings** | HuggingFace (all-mpnet-base-v2) |
| **Vector DB** | ChromaDB |
| **Chunking** | SemanticChunker (LangChain) |

## ğŸ¯ Use Cases

### Research Papers
- Collection: "ml_papers" - Machine Learning research
- Collection: "quantum_papers" - Quantum Computing papers
- Collection: "bio_papers" - Biology research

### Project Documentation
- Collection: "project_alpha" - Alpha project docs
- Collection: "project_beta" - Beta project docs
- Collection: "project_gamma" - Gamma project docs

### Multi-Domain Knowledge Base
- Collection: "technical_docs" - Technical documentation
- Collection: "business_docs" - Business documents
- Collection: "legal_docs" - Legal documents

## ğŸ§ª Testing

Run automated tests:
```bash
.venv\Scripts\python.exe test_collections.py
```

This will:
- Check API connectivity
- List all collections
- Test querying each collection

## ğŸ“‚ Project Structure

```
chatbot-application-with-RAG/
â”œâ”€â”€ api.py                      # FastAPI backend
â”œâ”€â”€ app_api.py                  # Streamlit UI (API version)
â”œâ”€â”€ app.py                      # Streamlit UI (direct version)
â”œâ”€â”€ query.py                    # RAG query logic
â”œâ”€â”€ ingest.py                   # Document ingestion
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ test_collections.py         # Automated tests
â”œâ”€â”€ QUICKSTART.md              # Quick start guide
â”œâ”€â”€ MULTI_COLLECTION_GUIDE.md  # Collection guide
â”œâ”€â”€ ARCHITECTURE.md            # Architecture docs
â”œâ”€â”€ IMPLEMENTATION_SUMMARY.md  # Technical details
â””â”€â”€ Vector_DB/                 # ChromaDB storage
    â”œâ”€â”€ my_docss/              # Default collection
    â”œâ”€â”€ research_papers/        # Custom collection
    â””â”€â”€ technical_docs/         # Custom collection
```

## ğŸ”Œ API Endpoints

### GET /health
Check API health and database status

### GET /collections
List all collections with chunk counts

### POST /query
Query a specific collection
```json
{
  "question": "What is a transformer?",
  "collection_name": "research_papers"
}
```

### POST /ingest
Ingest PDF to collection
```
Form Data:
- file: PDF file
- collection_name: "my_collection"
```

### DELETE /database
Delete entire database or specific collection
```
Query Parameter:
- collection_name: "specific_collection" (optional)
```

## ğŸ¨ UI Features

- **Collection Selector** - Dropdown to choose active collection
- **Chat Interface** - Multi-session chat history
- **Source Chunks** - Expandable view of retrieved context
- **Document Upload** - Drag-and-drop PDF ingestion
- **Collection Info** - Display chunk counts per collection
- **Session Management** - Create, switch, delete chat sessions

## ğŸ” Environment Variables

Required in `.env` file:
```
GOOGLE_API_KEY=your_gemini_api_key_here
```

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“ License

[Your License Here]

## ğŸ™ Acknowledgments

- LangChain for RAG framework
- Google for Gemini API
- HuggingFace for embeddings
- ChromaDB for vector storage
- Streamlit for UI framework

## ğŸ“ Support

For issues or questions:
- Check documentation in `/docs` folder
- Review API docs at http://localhost:8000/docs
- Open an issue on GitHub

---

**Version**: 2.0.0  
**Status**: Production Ready âœ…  
**Multi-Collection Support**: Enabled ğŸ‰

Made with â¤ï¸ for better document intelligence